import type {
  LanguageModelV3FinishReason,
  LanguageModelV3GenerateResult,
  LanguageModelV3StreamPart,
} from "@ai-sdk/provider";
import { simulateReadableStream } from "ai";
import { MockLanguageModelV3 } from "ai/test";
import { getResponseChunksByPrompt } from "@/tests/prompts/utils";

const mockUsage = {
  inputTokens: { total: 10, noCache: 10, cacheRead: 0, cacheWrite: 0 },
  outputTokens: { total: 20, text: 20, reasoning: 0 },
};

const finishReason: LanguageModelV3FinishReason = {
  unified: "stop",
  raw: "stop",
};

const createMockGenerateResult = (
  text: string
): LanguageModelV3GenerateResult => ({
  finishReason,
  usage: mockUsage,
  content: [{ type: "text", text }],
  warnings: [],
});

export const chatModel = new MockLanguageModelV3({
  doGenerate: async (_options) => createMockGenerateResult("Hello, world!"),
  doStream: async ({ prompt }) => ({
    stream: simulateReadableStream({
      chunkDelayInMs: 500,
      initialDelayInMs: 1000,
      chunks: getResponseChunksByPrompt(prompt),
    }),
  }),
});

export const reasoningModel = new MockLanguageModelV3({
  doGenerate: async (_options) => createMockGenerateResult("Hello, world!"),
  doStream: async ({ prompt }) => ({
    stream: simulateReadableStream({
      chunkDelayInMs: 500,
      initialDelayInMs: 1000,
      chunks: getResponseChunksByPrompt(prompt, true),
    }),
  }),
});

const titleChunks: LanguageModelV3StreamPart[] = [
  { id: "1", type: "text-start" },
  { id: "1", type: "text-delta", delta: "This is a test title" },
  { id: "1", type: "text-end" },
  {
    type: "finish",
    finishReason,
    usage: mockUsage,
  },
];

export const titleModel = new MockLanguageModelV3({
  doGenerate: async (_options) =>
    createMockGenerateResult("This is a test title"),
  doStream: async (_options) => ({
    stream: simulateReadableStream({
      chunkDelayInMs: 500,
      initialDelayInMs: 1000,
      chunks: titleChunks,
    }),
  }),
});

export const artifactModel = new MockLanguageModelV3({
  doGenerate: async (_options) => createMockGenerateResult("Hello, world!"),
  doStream: async ({ prompt }) => ({
    stream: simulateReadableStream({
      chunkDelayInMs: 50,
      initialDelayInMs: 100,
      chunks: getResponseChunksByPrompt(prompt),
    }),
  }),
});
